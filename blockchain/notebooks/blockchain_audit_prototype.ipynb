{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Blockchain Audit Prototype\n",
        "## BizClear - Immutable Audit Trail Demo\n",
        "\n",
        "**Why blockchain:** Immutability guarantees for permit and inspection records. Cryptographic hashes ensure tamper detection.\n",
        "\n",
        "**Prerequisites:** Run `docker-compose up -d ganache` and deploy contracts (or `docker-compose up` for full stack).\n",
        "\n",
        "**RPC:** Ganache at localhost:7545 (host) or localhost:8545 (if running notebook inside Docker)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Connect to the blockchain. Checks if we're connected and shows the latest block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from web3 import Web3\n",
        "\n",
        "RPC_URL = 'http://127.0.0.1:7545'\n",
        "BUILD_DIR = Path('../build/contracts')\n",
        "\n",
        "w3 = Web3(Web3.HTTPProvider(RPC_URL))\n",
        "print(f'Connected: {w3.is_connected()}')\n",
        "print(f'Block number: {w3.eth.block_number}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Contract ABIs and Addresses\n",
        "\n",
        "Load the AuditLog contract so we can talk to it. (Gets the contract info from the build folder.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, re\n",
        "\n",
        "def _camel_to_snake(name):\n",
        "    \"\"\"AuditLog -> AUDIT_LOG, DocumentStorage -> DOCUMENT_STORAGE\"\"\"\n",
        "    return re.sub(r'(?<=[a-z0-9])(?=[A-Z])', '_', name).upper()\n",
        "\n",
        "def load_contract(name):\n",
        "    \"\"\"Load contract ABI from build dir; get address from .env first, then build artifact.\"\"\"\n",
        "    path = BUILD_DIR / f'{name}.json'\n",
        "    with open(path) as f:\n",
        "        data = json.load(f)\n",
        "    abi = data['abi']\n",
        "\n",
        "    # 1) Prefer address from .env (deploy-contracts keeps this current across Ganache restarts)\n",
        "    #    Try multiple key formats: AUDIT_LOG_CONTRACT_ADDRESS, AUDITLOG_CONTRACT_ADDRESS\n",
        "    snake = _camel_to_snake(name)  # AuditLog -> AUDIT_LOG\n",
        "    addr = (os.getenv(f'{snake}_CONTRACT_ADDRESS')\n",
        "            or os.getenv(f'{name.upper()}_CONTRACT_ADDRESS'))\n",
        "\n",
        "    # 2) Fall back to build artifact (may be stale after Ganache restart)\n",
        "    if not addr:\n",
        "        networks = data.get('networks', {})\n",
        "        addr = next((n.get('address') for n in networks.values() if n.get('address')), None)\n",
        "\n",
        "    if not addr:\n",
        "        raise FileNotFoundError(f'No deployed address for {name}. Run: docker-compose up deploy-contracts')\n",
        "\n",
        "    addr = Web3.to_checksum_address(addr)\n",
        "\n",
        "    # Sanity check: is there actually code at this address?\n",
        "    if w3.eth.get_code(addr) == b'':\n",
        "        raise RuntimeError(\n",
        "            f'No contract code at {addr} for {name}. '\n",
        "            'Ganache may have restarted. Run: docker-compose up deploy-contracts'\n",
        "        )\n",
        "\n",
        "    return w3.eth.contract(address=addr, abi=abi)\n",
        "\n",
        "# Load .env so contract addresses are available\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv(Path().resolve().parent.parent / '.env', override=True)\n",
        "except (ImportError, Exception):\n",
        "    pass\n",
        "\n",
        "audit_log = load_contract('AuditLog')\n",
        "print('AuditLog loaded at', audit_log.address)\n",
        "\n",
        "# Also load AccessControl so we can check roles\n",
        "access_control = load_contract('AccessControl')\n",
        "print('AccessControl loaded at', access_control.address)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Audit Trail Demo - Log Hash\n",
        "\n",
        "Turn sample data into a hash and log it on-chain. Uses the deployer account (has AUDITOR_ROLE) — same key as audit-service, no setup needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n",
        "from eth_account import Account\n",
        "\n",
        "# Read deployer key from .env (no hardcoded fallback — avoids key leakage if notebook is shared)\n",
        "DEPLOYER_KEY = os.getenv('DEPLOYER_PRIVATE_KEY')\n",
        "if not DEPLOYER_KEY:\n",
        "    raise RuntimeError(\n",
        "        'DEPLOYER_PRIVATE_KEY not set. Add it to .env (Ganache first account from mnemonic).\\n'\n",
        "        'Run: docker-compose up  (deploy-contracts writes it to .env automatically)'\n",
        "    )\n",
        "account = Account.from_key(DEPLOYER_KEY)\n",
        "\n",
        "if w3.eth.get_balance(account.address) == 0:\n",
        "    raise RuntimeError(f'Account {account.address} has no ETH. Is Ganache running? Is the key correct?')\n",
        "\n",
        "# Check AUDITOR_ROLE on AccessControl\n",
        "try:\n",
        "    auditor_role = access_control.functions.AUDITOR_ROLE().call()\n",
        "    has_role = access_control.functions.hasRole(account.address, auditor_role).call()\n",
        "    ac_owner = access_control.functions.owner().call()\n",
        "    print(f'AccessControl owner: {ac_owner}')\n",
        "    print(f'Account has AUDITOR_ROLE: {has_role}')\n",
        "    if not has_role:\n",
        "        print(f'⚠ Account {account.address} does NOT have AUDITOR_ROLE!')\n",
        "        print(f'  AccessControl owner is {ac_owner} — that account has the role.')\n",
        "        print(f'  Fix: either use the owner key, or grant AUDITOR_ROLE to this account.')\n",
        "except Exception as e:\n",
        "    print(f'Could not check AUDITOR_ROLE: {e}')\n",
        "\n",
        "print(f'Using account: {account.address} (balance: {w3.from_wei(w3.eth.get_balance(account.address), \"ether\"):.2f} ETH)')\n",
        "\n",
        "event_data = 'permit_application_submitted_2024'\n",
        "h = hashlib.sha256(event_data.encode()).digest()\n",
        "hash_b32 = bytes.fromhex(h.hex())\n",
        "print(f'SHA256 hash (hex): {h.hex()}')\n",
        "\n",
        "# Log hash on-chain (deployer has AUDITOR_ROLE)\n",
        "try:\n",
        "    tx = audit_log.functions.logAuditHash(hash_b32, 'permit_application_submitted').build_transaction({\n",
        "        'from': account.address,\n",
        "        'gas': 300000,\n",
        "        'nonce': w3.eth.get_transaction_count(account.address),\n",
        "        'chainId': w3.eth.chain_id,\n",
        "    })\n",
        "    signed = account.sign_transaction(tx)\n",
        "    tx_hash = w3.eth.send_raw_transaction(signed.raw_transaction)\n",
        "    receipt = w3.eth.wait_for_transaction_receipt(tx_hash)\n",
        "    if receipt.status == 0:\n",
        "        print(f'\\n⚠ TX REVERTED! Tx: {receipt.transactionHash.hex()}  gasUsed: {receipt.gasUsed}')\n",
        "        print('  Possible causes: AUDITOR_ROLE missing, hash already exists, or gas too low.')\n",
        "    else:\n",
        "        print(f'\\nLogged on-chain! Tx: {receipt.transactionHash.hex()}  gasUsed: {receipt.gasUsed}')\n",
        "except Exception as e:\n",
        "    if 'Hash already exists' in str(e):\n",
        "        print('\\nHash already on-chain (logged previously).')\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Tamper Detection - Verify Hash\n",
        "\n",
        "Check if a hash exists on-chain. If someone changed the data, the hash would be different — so we'd know it was tampered with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use SHA256 (same as backend) for bytes32\n",
        "hash_b32 = bytes.fromhex(h.hex())\n",
        "exists = audit_log.functions.hashExists(hash_b32).call()\n",
        "print(f'Hash exists on-chain: {exists}')\n",
        "\n",
        "# Modified data would produce different hash - tamper detection\n",
        "tampered_data = 'permit_application_submitted_2024_TAMPERED'\n",
        "h_tampered = hashlib.sha256(tampered_data.encode()).digest()\n",
        "exists_tampered = audit_log.functions.hashExists(h_tampered).call()\n",
        "print(f'Tampered hash exists: {exists_tampered}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Security Analysis - onlyOwner / Re-entrancy\n",
        "\n",
        "Only auditors can log hashes. The contract uses proven patterns to stay secure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('AuditLog uses onlyAuditor modifier - only AUDITOR_ROLE can log.')\n",
        "print('AccessControl provides role checks. Re-entrancy mitigated by OpenZeppelin patterns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Performance Metrics\n",
        "\n",
        "Shows the latest block and gas limit. (Basic info about the chain.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block = w3.eth.get_block('latest')\n",
        "print(f'Latest block: {block[\"number\"]}')\n",
        "print(f'Gas limit: {block[\"gasLimit\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Prototype Vulnerabilities & Limitations\n",
        "\n",
        "| Area | Vulnerability / Limitation | Impact | Status |\n",
        "|------|----------------------------|--------|--------|\n",
        "| **Single auditor role** | One deployer has AUDITOR_ROLE; no multi-sig or key rotation | Compromised key = attacker can log false hashes | Open |\n",
        "| **No gas limits on readers** | `getAuditHashCount()` + loop over entries can grow unbounded | DoS if logs grow large; need pagination | Open |\n",
        "| **Ganache = dev only** | Local chain; no finality, no real decentralization | Not suitable for production; needs mainnet/testnet | Open |\n",
        "| ~~Private key in notebook~~ | ~~Hardcoded fallback key~~ | ~~Key exposure if notebook shared~~ | **Fixed** — reads from .env only |\n",
        "| ~~Gradio share link~~ | ~~`share=True` always on~~ | ~~Traffic visible to Gradio servers~~ | **Fixed** — off by default, opt-in via `GRADIO_SHARE=1` |\n",
        "| ~~No service-to-service auth~~ | ~~Anyone could call audit write endpoints~~ | ~~Unauthorized audit log injection~~ | **Fixed** — `X-API-Key` required on write endpoints |\n",
        "| ~~No rate limiting~~ | ~~Unbounded writes to blockchain~~ | ~~DoS via rapid log submissions~~ | **Fixed** — rate limiter on `/api/audit/log` |\n",
        "| ~~Hash-only verification~~ | ~~No way to check if data matches an on-chain hash~~ | ~~Can't verify data integrity from content~~ | **Fixed** — `/verify-data` + Gradio \"Verify Data\" tab |\n",
        "| ~~Least privilege~~ | ~~Any user could query any user's audit history~~ | ~~Unauthorized data access~~ | **Fixed** — non-admins see only own logs |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Embedded Prototype UI (Gradio)\n",
        "\n",
        "View audit logs, verify hashes, and run test scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import hashlib\n",
        "import time\n",
        "import traceback as _tb\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Rate limiting: max 5 logs per 60 seconds (app-level; contract has no built-in limit)\n",
        "_RATE_LIMIT_LOGS = []\n",
        "_RATE_LIMIT_MAX = 5\n",
        "_RATE_LIMIT_WINDOW = 60\n",
        "\n",
        "def _check_rate_limit():\n",
        "    now = time.time()\n",
        "    _RATE_LIMIT_LOGS[:] = [t for t in _RATE_LIMIT_LOGS if now - t < _RATE_LIMIT_WINDOW]\n",
        "    if len(_RATE_LIMIT_LOGS) >= _RATE_LIMIT_MAX:\n",
        "        return False, f'Rate limit: max {_RATE_LIMIT_MAX} logs per {_RATE_LIMIT_WINDOW}s. Try again later.'\n",
        "    _RATE_LIMIT_LOGS.append(now)\n",
        "    return True, None\n",
        "\n",
        "# Debug log buffer — collects messages shown in the Console\n",
        "_debug_lines = []\n",
        "\n",
        "def _debug(msg):\n",
        "    ts = datetime.now(timezone.utc).strftime('%H:%M:%S')\n",
        "    line = f'[{ts}] {msg}'\n",
        "    _debug_lines.append(line)\n",
        "    if len(_debug_lines) > 200:\n",
        "        del _debug_lines[:len(_debug_lines) - 200]\n",
        "\n",
        "def _get_debug_log():\n",
        "    return '\\n'.join(_debug_lines) if _debug_lines else '(no debug messages yet)'\n",
        "\n",
        "def _fetch_audit_logs(limit=50):\n",
        "    \"\"\"Fetch audit hash entries from contract into a table.\"\"\"\n",
        "    try:\n",
        "        count = audit_log.functions.getAuditHashCount().call()\n",
        "        _debug(f'getAuditHashCount() = {count}  (contract: {audit_log.address})')\n",
        "        rows = []\n",
        "        for i in range(min(int(count), limit)):\n",
        "            try:\n",
        "                entry = audit_log.functions.auditHashEntries(i).call()\n",
        "                _debug(f'  entry[{i}] raw: {entry}')\n",
        "                hash_hex = entry[0].hex() if isinstance(entry[0], bytes) else str(entry[0])\n",
        "                event_type = str(entry[1])\n",
        "                ts = int(entry[2])\n",
        "                addr = str(entry[3])\n",
        "                dt = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC') if ts else ''\n",
        "                rows.append([str(i + 1), hash_hex, event_type, dt, addr])\n",
        "            except Exception as inner_e:\n",
        "                _debug(f'  entry[{i}] ERROR: {inner_e}')\n",
        "                rows.append([str(i + 1), 'ERROR', str(inner_e), '-', '-'])\n",
        "        if not rows:\n",
        "            _debug('No entries found — returning placeholder row')\n",
        "            return [['—', '(no entries)', '—', '—', '—']]\n",
        "        _debug(f'Returning {len(rows)} rows')\n",
        "        return rows\n",
        "    except Exception as e:\n",
        "        _debug(f'_fetch_audit_logs EXCEPTION: {e}\\n{\"\".join(_tb.format_exception(e))}')\n",
        "        return [['!', f'Error: {e}', '—', '—', '—']]\n",
        "\n",
        "def _table_as_text():\n",
        "    \"\"\"Fetch logs and return as tab-separated text for easy copying.\"\"\"\n",
        "    rows = _fetch_audit_logs(100)\n",
        "    lines = ['#\\tHash\\tEvent Type\\tTimestamp\\tLogged By']\n",
        "    for r in rows:\n",
        "        lines.append('\\t'.join(r))\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "def verify_hash_ui(hash_hex):\n",
        "    try:\n",
        "        h = bytes.fromhex(hash_hex.replace('0x', '').strip())\n",
        "        if len(h) != 32:\n",
        "            return 'Invalid hash length (expected 32 bytes / 64 hex chars)'\n",
        "        exists, ts = audit_log.functions.verifyHash(h).call()\n",
        "        dt = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC') if ts else '-'\n",
        "        return f'Exists: {exists}\\nTimestamp: {dt}'\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def verify_data_ui(original_data):\n",
        "    \"\"\"Verify original data against on-chain hash.\"\"\"\n",
        "    if not original_data or not original_data.strip():\n",
        "        return 'Enter data to verify.'\n",
        "    try:\n",
        "        h = hashlib.sha256(original_data.encode()).digest()\n",
        "        hash_b32 = bytes.fromhex(h.hex())\n",
        "        exists, ts = audit_log.functions.verifyHash(hash_b32).call()\n",
        "        dt = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC') if ts else '-'\n",
        "        if exists:\n",
        "            return f'Verified: data matches on-chain hash.\\nHash: {h.hex()}\\nLogged: {dt}'\n",
        "        return f'Not found: data does not match any stored hash.\\nComputed hash: {h.hex()}'\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def log_test_scenario(event_type, event_data):\n",
        "    \"\"\"Log a test audit hash. Returns (result, logs, console).\"\"\"\n",
        "    if not event_type or not event_data:\n",
        "        return 'Enter event type and data.', _fetch_audit_logs(20), _get_debug_log()\n",
        "    ok, err = _check_rate_limit()\n",
        "    if not ok:\n",
        "        return err, _fetch_audit_logs(20), _get_debug_log()\n",
        "    try:\n",
        "        h = hashlib.sha256(event_data.encode()).digest()\n",
        "        hash_b32 = bytes.fromhex(h.hex())\n",
        "        _debug(f'Logging hash: {h.hex()} eventType: {event_type}')\n",
        "        _debug(f'  contract: {audit_log.address}  account: {account.address}')\n",
        "        tx = audit_log.functions.logAuditHash(hash_b32, event_type).build_transaction({\n",
        "            'from': account.address, 'gas': 300000,\n",
        "            'nonce': w3.eth.get_transaction_count(account.address), 'chainId': w3.eth.chain_id,\n",
        "        })\n",
        "        signed = account.sign_transaction(tx)\n",
        "        tx_hash = w3.eth.send_raw_transaction(signed.raw_transaction)\n",
        "        receipt = w3.eth.wait_for_transaction_receipt(tx_hash)\n",
        "        status = receipt.get('status', 'N/A')\n",
        "        _debug(f'  tx: {receipt[\"transactionHash\"].hex()}  status: {status}  gasUsed: {receipt.get(\"gasUsed\", \"?\")}')\n",
        "        if status == 0:\n",
        "            _debug('  ⚠ TX REVERTED (status=0) — check AUDITOR_ROLE or hash collision')\n",
        "        msg = f'Logged! Hash: {h.hex()}\\nTx: {receipt[\"transactionHash\"].hex()}\\nStatus: {status}'\n",
        "        return msg, _fetch_audit_logs(20), _get_debug_log()\n",
        "    except Exception as e:\n",
        "        _debug(f'log_test_scenario ERROR: {e}\\n{\"\".join(_tb.format_exception(e))}')\n",
        "        return f'Error: {e}', _fetch_audit_logs(20), _get_debug_log()\n",
        "\n",
        "def run_test_scenario(scenario):\n",
        "    \"\"\"Run predefined test scenarios. Returns (result, logs, console).\"\"\"\n",
        "    if not scenario:\n",
        "        return 'Select a scenario.', _fetch_audit_logs(20), _get_debug_log()\n",
        "    _debug(f'Running scenario: {scenario}')\n",
        "    if scenario == 'Log sample permit':\n",
        "        return log_test_scenario('permit_application_submitted', 'permit_sample_2024')\n",
        "    if scenario == 'Verify known hash':\n",
        "        result = verify_hash_ui('7f64fe1375f7dbda9f4d2b1973015c0db8f60753f621067e29fd54c961ce46f4')\n",
        "        return result, _fetch_audit_logs(20), _get_debug_log()\n",
        "    if scenario == 'Verify known data':\n",
        "        result = verify_data_ui('permit_application_submitted_2024')\n",
        "        return result, _fetch_audit_logs(20), _get_debug_log()\n",
        "    if scenario == 'Tamper check':\n",
        "        result = verify_hash_ui(hashlib.sha256(b'permit_TAMPERED').hex()) + '\\n(Expected: false — hash not logged)'\n",
        "        return result, _fetch_audit_logs(20), _get_debug_log()\n",
        "    return 'Unknown scenario.', _fetch_audit_logs(20), _get_debug_log()\n",
        "\n",
        "def _startup_load():\n",
        "    _debug(f'Startup — contract: {audit_log.address}  account: {account.address}')\n",
        "    _debug(f'  balance: {w3.from_wei(w3.eth.get_balance(account.address), \"ether\"):.2f} ETH')\n",
        "    return _fetch_audit_logs(20), _get_debug_log()\n",
        "\n",
        "def _refresh_all():\n",
        "    return _fetch_audit_logs(20), _get_debug_log()\n",
        "\n",
        "# ─── Gradio UI ───────────────────────────────────────────────────────────────\n",
        "with gr.Blocks(title='BizClear Blockchain Audit Prototype', theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown('# BizClear Blockchain Audit Prototype')\n",
        "    gr.Markdown('View logs, verify hashes, and run test scenarios.  \\n'\n",
        "                '*Tip: click any text field → Ctrl+A → Ctrl+C to copy.*')\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem('View Audit Logs'):\n",
        "            logs_table = gr.Dataframe(\n",
        "                headers=['#', 'Hash', 'Event Type', 'Timestamp', 'Logged By'],\n",
        "                datatype=['str', 'str', 'str', 'str', 'str'],\n",
        "                label='Audit Hash Logs (on-chain)',\n",
        "                wrap=True,\n",
        "            )\n",
        "            refresh_btn = gr.Button('Refresh Logs')\n",
        "            export_btn = gr.Button('Export as Text')\n",
        "            export_out = gr.Textbox(label='Exported Table (select all → copy)', lines=6, interactive=True)\n",
        "\n",
        "        with gr.TabItem('Verify Hash'):\n",
        "            hash_in = gr.Textbox(label='SHA256 Hash (hex, 64 chars)', placeholder='7f64fe13...')\n",
        "            verify_out = gr.Textbox(label='Result', lines=3, interactive=True)\n",
        "            verify_hash_btn = gr.Button('Verify')\n",
        "\n",
        "        with gr.TabItem('Verify Data'):\n",
        "            data_in = gr.Textbox(label='Original data (content to verify)', placeholder='permit_application_submitted_2024', lines=3)\n",
        "            data_verify_out = gr.Textbox(label='Result', lines=3, interactive=True)\n",
        "            verify_data_btn = gr.Button('Verify')\n",
        "\n",
        "        with gr.TabItem('Log Test Event'):\n",
        "            evt_type = gr.Textbox(label='Event Type', value='permit_application_submitted')\n",
        "            evt_data = gr.Textbox(label='Event Data (will be hashed)', value='test_permit_2024')\n",
        "            log_out = gr.Textbox(label='Result', lines=4, interactive=True)\n",
        "            log_btn = gr.Button('Log on-chain')\n",
        "\n",
        "        with gr.TabItem('Test Scenarios'):\n",
        "            scenario_dd = gr.Dropdown(\n",
        "                choices=['Log sample permit', 'Verify known hash', 'Verify known data', 'Tamper check'],\n",
        "                label='Scenario',\n",
        "            )\n",
        "            scenario_out = gr.Textbox(label='Result', lines=4, interactive=True)\n",
        "            run_btn = gr.Button('Run')\n",
        "\n",
        "    gr.Markdown('### Console')\n",
        "    console_box = gr.Textbox(label='Debug Log (errors, contract calls, tx status)', lines=12, interactive=True)\n",
        "    refresh_console_btn = gr.Button('Refresh Console')\n",
        "\n",
        "    # Wire up events\n",
        "    refresh_btn.click(fn=_refresh_all, outputs=[logs_table, console_box])\n",
        "    export_btn.click(fn=_table_as_text, outputs=export_out)\n",
        "    verify_hash_btn.click(fn=verify_hash_ui, inputs=hash_in, outputs=verify_out)\n",
        "    verify_data_btn.click(fn=verify_data_ui, inputs=data_in, outputs=data_verify_out)\n",
        "    log_btn.click(fn=log_test_scenario, inputs=[evt_type, evt_data], outputs=[log_out, logs_table, console_box])\n",
        "    run_btn.click(fn=run_test_scenario, inputs=scenario_dd, outputs=[scenario_out, logs_table, console_box])\n",
        "    refresh_console_btn.click(fn=_get_debug_log, outputs=console_box)\n",
        "    demo.load(fn=_startup_load, outputs=[logs_table, console_box])\n",
        "\n",
        "_share = os.getenv('GRADIO_SHARE', '').strip() in ('1', 'true', 'True')\n",
        "demo.launch(share=_share)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
