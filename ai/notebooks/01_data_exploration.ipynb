{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "from preprocessing.preprocess import load_csv, clean_data, preprocess_for_model\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c74e3",
   "metadata": {},
   "source": [
    "## Load & Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV dataset\n",
    "# Update path to your dataset\n",
    "dataset_path = '../datasets/sample_toy.csv'\n",
    "\n",
    "df = load_csv(dataset_path)\n",
    "\n",
    "print(f\"Dataset loaded from: {dataset_path}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(df.memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing[missing > 0])\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    print(f\"\\nMissing percentage:\")\n",
    "    print(missing_pct[missing_pct > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba065348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa842494",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"Duplicate percentage: {(duplicates / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type distribution\n",
    "print(\"Data type distribution:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric columns ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307305fa",
   "metadata": {},
   "source": [
    "## Explore Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc49227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "print(\"Label distribution:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "print(f\"\\nLabel percentages:\")\n",
    "print(df['label'].value_counts(normalize=True).round(4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar plot\n",
    "df['label'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Label Distribution (Count)')\n",
    "axes[0].set_xlabel('Label')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y')\n",
    "\n",
    "# Pie chart\n",
    "df['label'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "axes[1].set_title('Label Distribution (Percentage)')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebe1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class imbalance\n",
    "label_counts = df['label'].value_counts().sort_values()\n",
    "imbalance_ratio = label_counts.max() / label_counts.min()\n",
    "print(f\"Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"Warning: Dataset is imbalanced. Consider using class weights or resampling.\")\n",
    "else:\n",
    "    print(\"Dataset is well-balanced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce6754",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "if 'label' in numeric_cols:\n",
    "    corr_with_label = df[numeric_cols].corr()['label'].drop('label').sort_values(ascending=False)\n",
    "    print(\"Feature correlation with label:\")\n",
    "    print(corr_with_label)\n",
    "else:\n",
    "    # For binary/categorical labels, calculate point-biserial correlation\n",
    "    from scipy.stats import pointbiserialr\n",
    "    numeric_only = df[numeric_cols]\n",
    "    corr_dict = {}\n",
    "    for col in numeric_cols:\n",
    "        corr, _ = pointbiserialr(df['label'], df[col])\n",
    "        corr_dict[col] = abs(corr)\n",
    "    corr_series = pd.Series(corr_dict).sort_values(ascending=False)\n",
    "    print(\"Feature correlation with label (absolute):\")\n",
    "    print(corr_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9051f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top feature correlations\n",
    "if 'label' in numeric_cols:\n",
    "    corr_with_label = df[numeric_cols].corr()['label'].drop('label').sort_values()\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    corr_with_label.plot(kind='barh', ax=ax, color='steelblue')\n",
    "    ax.set_title('Feature Correlation with Label')\n",
    "    ax.set_xlabel('Correlation Coefficient')\n",
    "    ax.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862972a0",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d08a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Rows removed %: {((len(df) - len(df_clean)) / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c162c",
   "metadata": {},
   "source": [
    "## Prepare for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits with preprocessing\n",
    "prep = preprocess_for_model(df_clean, label_col='label')\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nData split information:\")\n",
    "print(f\"Training   - X: {prep['X_train'].shape}, y: {prep['y_train'].shape}\")\n",
    "print(f\"Validation - X: {prep['X_val'].shape}, y: {prep['y_val'].shape}\")\n",
    "print(f\"Test       - X: {prep['X_test'].shape}, y: {prep['y_test'].shape}\")\n",
    "print(f\"\\nFeatures used: {prep['feature_columns']}\")\n",
    "print(f\"Scaler: {type(prep['scaler']).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61703e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no data leakage and splits make sense\n",
    "X_train, y_train = prep['X_train'], prep['y_train']\n",
    "X_val, y_val = prep['X_val'], prep['y_val']\n",
    "X_test, y_test = prep['X_test'], prep['y_test']\n",
    "\n",
    "total_samples = len(y_train) + len(y_val) + len(y_test)\n",
    "print(f\"Total samples accounted for: {total_samples} (original: {len(df_clean)})\")\n",
    "\n",
    "print(f\"\\nTrain/Val/Test split:\")\n",
    "print(f\"  Train: {(len(y_train)/len(df_clean)*100):.1f}%\")\n",
    "print(f\"  Val:   {(len(y_val)/len(df_clean)*100):.1f}%\")\n",
    "print(f\"  Test:  {(len(y_test)/len(df_clean)*100):.1f}%\")\n",
    "\n",
    "print(f\"\\nLabel distribution in splits:\")\n",
    "print(f\"  Train - Class 0: {(y_train == 0).sum()}, Class 1: {(y_train == 1).sum()}\")\n",
    "print(f\"  Val   - Class 0: {(y_val == 0).sum()}, Class 1: {(y_val == 1).sum()}\")\n",
    "print(f\"  Test  - Class 0: {(y_test == 0).sum()}, Class 1: {(y_test == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a81253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data preprocessing (scaling)\n",
    "print(f\"Training data statistics (after scaling):\")\n",
    "print(f\"  Mean: {X_train.mean(axis=0)[:5]}... (first 5 features)\")\n",
    "print(f\"  Std:  {X_train.std(axis=0)[:5]}... (first 5 features)\")\n",
    "print(f\"  Min:  {X_train.min(axis=0)[:5]}... (first 5 features)\")\n",
    "print(f\"  Max:  {X_train.max(axis=0)[:5]}... (first 5 features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc10b8d",
   "metadata": {},
   "source": [
    "## Save Preprocessing Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51760717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save scaler for inference\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "scaler_path = 'models/scaler_sample.pkl'\n",
    "joblib.dump(prep['scaler'], scaler_path)\n",
    "\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "print(f\"Feature columns: {prep['feature_columns']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
